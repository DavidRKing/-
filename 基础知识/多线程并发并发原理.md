#### synchronized

线程安全问题的主要诱因

  存在共享数据(也称临界资源)

  存在多条线程共同操作这些共享数据

解决问题的根本办法：

  同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再对共享数据进行操作

#### 互斥锁特性

   互斥性:即在同一时间只允许一个线程持有某个对象锁，通过这种特性来实现多线程的协调机制，这样在同一时间只有一个线程对需要同步的代码块(符合操作)进行访问。互斥性也成为操作的原子性。

   可见性：必须确保在锁释放之前，对共享变量所做的修改，对于随后获得该锁的另一个线程是可见的(即在获得锁时应获得最新共享变量的值)，否则另一个线程可能是在本地缓存的某个副本上继续操作，从而引起不一致。

   synchronized锁的不是代码，锁的是对象。

#### 根据获取的锁的分类：获取对象锁和获取类锁

   获取对象锁的两种方法:

   1.同步代码块(synchronized(this)),synchronized(类实例对象),锁是小括号()中的实例对象。

   2.同步非静态方法(synchronized method),锁是当前对象的实例对象。

   例子不写了，so easy

  获取类锁的两种用法

​    1.同步代码块(synchronized(类.class)，锁是小括号()中的类对象(Class对象))。

​    2.同步静态方法(synchronized static method)，锁是当前对象的类对象(Class对象)。

#### synchronized底层实现原理

   实现synchronized的基础

​      Java对象头

​      Monitor

​         每个Java对象天生自带了一把看不见的锁。(重量级锁，对象头指针指向monitor)

​         

```c++
#objectMonitor.cpp
ObjectMonitor() {
    _header       = NULL;
    _count        = 0;
    _waiters      = 0,
    _recursions   = 0;
    _object       = NULL;
    _owner        = NULL;
    _WaitSet      = NULL;
    _WaitSetLock  = 0 ;
    _Responsible  = NULL ;
    _succ         = NULL ;
    _cxq          = NULL ;
    FreeNext      = NULL ;
    _EntryList    = NULL ;
    _SpinFreq     = 0 ;
    _SpinClock    = 0 ;
    OwnerIsThread = 0 ;
    _previous_owner_tid = 0;
  }
//waitSet等待池
//entryList锁池 
//_owner指向持有 object.monitor的线程
//每个线程会被封装成object waiter，保存在其中,当多个线程同步访问同一段同步代码时,先进入entryList
//当对象获取到monitor的时候，对象进入object区域，并将_owner设置为当前线程,monitor中的计数器count加1
//若对象调用wait()，释放monitor，owner=null,count -1。当前线程进入waitset，等待被唤醒
//如果线程执行结束，同样以上信息。
//对象锁。java代码加入了  monitor enter   moniterexit。如果代码发生了异常，如何释放锁？虚拟机自动加上异常处理。处理锁的释放
//类锁. 在静态方法上，flags ACC_SYNCHRONIZED
```

#### 重入

​        从互斥锁的设计上说，当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有独享锁的临界资源时，这种情况输入重入。



#### 对象在内存中的布局(hotspot)

   对象头

   

| 虚拟机位数 | 对象头结构             | 说明                                                         |
| ---------- | ---------------------- | ------------------------------------------------------------ |
| 32/64位    | Mark Work              | 默认存储对象的hashcode,分代年龄，锁类型，锁标志位等信息。    |
| 32/64位    | Class Metadata Address | 类型指针指向对象的类元数据，JVM通过这个指针确定该对象是哪个类的数据 |

 具体参加，并发编程的艺术(技术)忘了 。



   实例数据

   对其填充

#### 为什么会对synchronized嗤之以鼻

   早期版本中，synchronized属于重量级锁，依赖于Mutex Lock实现

   线程之间的切换需要从用户态切换到核心态，开销较大

   JDK6以后，synchronized性能得到了很大的提升。

#### 自旋锁与自适应自旋锁

  自旋锁

​      许多情况下，共享数据的锁定状态持续时间较短，切换线程不值得。

​      通过让线程执行忙循环等待锁的释放，不让出CPU( While(true)    Sleep 让出CPU)

​      缺点:若锁被其他线程长时间占用，会带来许多性能上的开销。PreBlockSpin

  自适应自旋锁:

​     自旋的次数不在固定

​     由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定(根据以往经验，来决定自旋次数)

  锁消除

​     JIT编译时，对运行上下文进行扫描，去除不可能存在竞争的锁。

  锁粗化

​    另一种极端

​    通过扩大加锁的范围，避免反复加锁和解锁

####  synchronized的四种状态

   无锁、偏向锁、轻量级锁、重量级锁

   锁膨胀的方向:无锁->偏向锁->轻量级锁->重量级锁

#####    偏向锁:减少同一线程获取锁的代价

​       大多数情况下，锁不存在多线程竞争，总是由同一线程多次获得

​       核心思想:如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word的结构也变为偏向锁结构，当该线程再次请求时，无需做任何同步操作，即获取锁的过程只需要检查Mark Word的锁标记位为偏向锁以及当前线程id等于Mark Word的Thread ID即可，这样就省去了大量有关锁申请的操作。

​      不适用于锁竞争比较激烈的多线程场合。

#####    轻量级锁

​      轻量级锁是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁。

​      适用的场景:线程交替执行同步块

​      若存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。

#####   锁的内存语义

​      当线程释放锁时，Java内存模型会把该线程对应的本地内存中的共享变量刷新到主内存中；

​      而当线程获取锁时，Java内存模型会把该线程对应的本地内存置为无效，从而使得被监视器保护的临界区代码必须从主内存中读取共享变量

#### 总结

| 锁       | 优点                                                         | 缺点                                           | 使用场景                                         |
| -------- | ------------------------------------------------------------ | ---------------------------------------------- | ------------------------------------------------ |
| 偏向锁   | 加锁和解锁不需要CAS操作，没有额外的性能消耗，和执行非同步方法相比仅存在纳秒级的差距 | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 | 只有一个线程或者同步方法的情景                   |
| 轻量级锁 | 竞争的线程不会阻塞，提高了响应速度                           | 若线程长时间抢不到锁，自旋会消耗cpu时间        | 线程交替执行同步块或者同步方法的场景             |
| 重量级锁 | 线程竞争不适用自旋锁，不会消耗CPU                            | 线程阻塞，同步块或者同步方法执行时间较长的场景 | 追求吞吐量，同步块或者同步方法执行时间较长的场景 |

#### synchronized和ReentrantLock的区别

   ReetrantLock  再入锁

   CountDownLatch、FutureTask、Semaphore一样基于AQS

   能够实现比synchronized更细粒度的控制，如公平性

   调用lock()之后，必须调用unlock()释放锁

   性能未必比synchronized高，并且也是可重入的。

   公平性:

​       ReetrantLock faireLock = new ReetrantLock(true);

​      倾向于将锁赋予等待时间最久的线程。

​      公平锁:获取锁的顺序按先后调用lock()方法的顺序(慎用)

​      非公平锁:抢占的顺序不一定，看运气

​      synchronized是非公平锁     

   ReentrantLock将锁对象化

​      判断是否有线程，或者某个特定线程，在排队等待获取锁

​      带超时的获取锁的尝试

​      感知有没有成功获取锁

   ArrayBlockingQueue   ReetranctLock实现  condition

 总结:

​          synchronized关键字，ReentrantLock是类

​          ReetrantLock可以对获取锁的时间进行设置，避免死锁

​         ReentrantLock可以获取各种锁的信息

​        ReetrantLock可以灵活地实现多路通知

​       机制：sync操作markword，lock调用Unsafe类的park()方法

#### Java内存模型中happens-before

   Java内存模型JMM

​       本身是一种抽象概念，并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量(包括实例字段，静态字段和构成数组对象的元素)的访问方式。

​       图不画了， so  easy

  JMM中的主内存

​       存储java实例对象

​       包括成员变量，类信息，常量，静态变量等。

​       属于数据共享的区域，多线程并发操作时会引发线程安全问题。

JMM中的工作内存

​       存储当前方法的所有本地变量信息，本地变量对其他线程不可见。

​       字节码行号指示器、Native方法等

​       属于线程私有数据区域，不存在线程安全问题。

JMM与Java内存区域划分是不同概念层次

​       JMM描述的是一组规则，围绕原子性，有序性，可见性展开

​       相似点：存在共享区域和私有区域

主内存与工作内存的数据存储类型以及操作方式归纳

​       方法里的基本数据类型本地变量将直接存储在工作内存的栈帧结构中

​       引用类型的本地变量:引用存储在工作内存中，实例存储在主内存中

​       成员变量、static变量、类信息均会被存储在主内存中

​       主内存共享的方式是线程各拷贝一份数据到工作内存中，操作完成后刷新回主内存。

##### 指令重排序需要满足的条件

​      在单线程环境下不能改变程序运行结果。

​      存在数据依赖关系的不允许重排序。 

​      无法通过happens-before原则推导出来的，才能进行指令的重排序。(JVM实现通过内存屏障)

​      A操作的结果需要对B操作可见，则A与B存在happens-before关系

```java
i=1;//线程A
j=i;//线程B
```

#####  Happens-before八大原则

1. 程序次序规则:一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作。

2. 锁定规则:一个unlock操作先行发生于后面对同一个锁的lock操作。

3. volatile变量规则:对一个变量的写操作先行发生于后面对这个变量的读操作。

4. 传递规则:如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C的结论

5. 线程启动规则:Thread对象的start()方法先行发生于次线程的每一个动作

6. 线程中断规则:对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生;

7. 线程终结规则:线程中所有的操作都线程发生于线程的终止检测,我们可以通过Thread.join()方法结束Thread.isAlive()的返回值手段检测到线程已经终止执行

8. 对象终结规则:一个对象的初始化完成先行发生于他的finalize()方法的开始

   

##### happens-before的概念

​    如果两个操作不满足上述任意一个happens-before规则，那么这两个操作就没有顺序的保障，jvm可以对这两个操作进行重排序；如果操作A happens-before操作B，那么操作A在内存上所做的操作对操作B都是可见的.

```java
private int value = 0;
public void write(int input){
    value = input;
} //线程A
public int read(){
    return read;
}//线程B

//两个方法不满足 happens-before规则，以上不是线程安全的，所以无法确定最终结果

```

##### volatile:JVM提供的轻量级同步机制

​    保证被volatile修饰的共享变量对所有线程总是可见的.

​    进制指令重排序优化

​    volatile可见性

```java
public class VolatileVisibility{
    public static volatile int value=0;
    public static void increase(){
        value++;
    }
}
//多线程可能看到相同的value值。所以并不是线程安全的。方法前需要加 synchronized


public class VolitaileSafe{
    volatile boolean shutdown;
    public void close(){
        shutdown=true;
    }
    public void doWork(){
        while(!shutdown){
            //dowork
        }
    }
}
//线程对shutdown修改，会对其他线程立即可见.
```

##### volatile变量为何立即可见?

  当写一个volatile变量时，JMM会把该线程对应的工作内存中的共享变量值刷新到主内存中；

  当读取一个volatile变量时，JMM会把该线程对应的工作内存置为无效.

##### volatile如何禁止重排序优化?

  内存屏障(Memory Barrier)

  1.保证特定操作的执行顺序

  2.保证某些变量的内存可见性

  通过插入内存屏障指令禁止在内存屏障前后的指令执行重排序优化

  强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本

```java
public class Singleton{
    private static Singleton instance;
    private Singleton(){}
    public static Singleton getInstance(){
        if(instance==null){
            synchronized(Singleton.class){
                //多线程环境下可能会出现问题
                instance=new Singleton();
            }
        }
        return instance;
    }
}
//经典问题:
//instance=new Singleton();
//memory=allocate(); 1.分配对象内存空间
//instance(memory);  2.初始化对象
//instance = memory  3.设置instance指向刚分配内存地址，instance!=null
//重排序 1,3,2：此时instance不为空，但是还没有初始化完毕。(单线程保证一致性，但是多线程无法保证)
//使用volatile修饰就可以解决这个问题

```

##### volatile和synchronized的区别

1.volatile本质是在告诉JVM当前变量在寄存器(工作内存)中的值是不确定的，需要从主内存中读取；synchronized则是锁定当前变量，只有当前线程可以访问变量，其他线程被阻塞住直到该线程完成变量操作为止。

2.volatile仅能使用在变量级别上，synchronized则可以使用在变量、方法和类级别.

3.volatile仅能实现变量的修改可见性，不能保证原子性，而synchronized则可以保证变量修改的可见性和原子性

4.volatile不会造成线程的阻塞;synchronized可能会造成线程的阻塞。

5.volatile标记的变量不会被编译器优化;synchronized标记的变量可以被编译器优化.